# Dependencies: Mindset and Background {#sec-dependencies-mindset-background}

```{r, echo = FALSE}
source("common.R")
status("restructuring")
```

## Introduction

A dependency is when your package uses functionality from another package (or other external tool).
In @sec-description-imports-suggests, we explained how to declare a dependency on another package by listing it in `Imports` or `Suggests`.
But that still leaves many issues for the maintainer to think about:

-   When should you take a dependency?
    What are the risk and rewards?

-   How should you use different kinds of dependencies in different contexts?
    I.e. imported vs. suggested packages, used inside your functions vs tests vs documentation.

A key concept we'll have to cover along the way is that of a *namespace*.
Your package's namespace is specified via its `NAMESPACE` file, which lays out the functions (or other objects) that your package exports for use by others.
The `NAMESPACE` file can also be used to import functions (or other objects) from your dependencies into your own package.
Although it can be a bit confusing, R's namespace system is vital for the package ecosystem.
It keeps each package encapsulated and self-contained.
This ensures that other packages won't interfere with your code, that your code won't interfere with other packages, and that your package works regardless of the environment in which it's run.

## When should you take a dependency? {#sec-dependencies-pros-cons}

*This section is adapted from the "It Depends" [blog post](https://www.tidyverse.org/blog/2019/05/itdepends/) and [talk](https://www.rstudio.com/resources/rstudioconf-2019/it-depends-a-dialog-about-dependencies/) authored by Jim Hester.*

Software dependencies can be a double-edged sword.

On one hand, they let you take advantage of others' work, giving your software new capabilities and making its behaviour and interface more consistent with other packages.
By using a pre-existing solution, you avoid re-implementing functionality, which eliminates many opportunities for you to introduce bugs.

On the other hand, your dependencies will likely change over time, which could require you to make changes to your package, potentially increasing your maintenance burden.
Your dependencies can also increase the time and disk space needed when users install your package.

These downsides have led some to suggest a 'dependency zero' mindset.
We feel that this is bad advice for most projects, and is likely to lead to lower functionality, increased maintenance, and new bugs.

### Dependencies are not equal

One problem with simply minimizing the absolute number of dependencies is that it treats all dependencies as equivalent, as if they all have the same costs and benefits (or even, infinite cost and no benefit).
However, in reality, this is far from the truth.
There are many axes upon which dependencies can differ, but some of the most important include:

1.  The type of the dependency.
    Some dependencies come bundled with R itself (e.g. base, utils, stats) or are one of the 'Recommended' packages (e.g. Matrix, survival).
    These packages are very low cost to depend on, as they are (nearly) universally installed on all users' systems, and mostly change only with new R versions.
    In contrast, there is a higher cost for a dependency that comes from, e.g., a non-CRAN repository, which requires users to configure additional repositories before installation.

2.  The number of upstream dependencies, i.e. recursive dependencies.
    For example, the [rlang](https://rlang.r-lib.org) package is intentionally managed as a low-level package and has no upstream dependencies apart from R itself.
    At the other extreme, there are packages on CRAN with \~250 recursive dependencies.

3.  Already fulfilled dependencies.
    If your package depends on dplyr then taking a dependency on tibble does not change the dependency footprint, as dplyr itself already depends on tibble.
    Additionally, some of the most popular packages (e.g. ggplot2) will already be installed on the majority of users' machines.
    So adding a ggplot2 dependency is unlikely to incur additional installation costs in most cases.

4.  The burden of installing the package.
    Various factors make a package more costly to install, in terms of time, space, and human aggravation:

    -   Time to compile: Packages that contain C/C++ can take very different amounts of time to install depending on the complexity of the code.
        For example, the [glue](https://glue.tidyverse.org) package takes \~5 seconds to compile on CRAN's build machines, whereas the [readr](https://readr.tidyverse.org) package takes \~100 seconds to install on the same machines.

    -   Binary package size: Users installing binary packages need to download them, so the size of the binary is relevant, particularly for those with slow internet connections.
        This also varies a great deal across packages.
        The smallest packages on CRAN are around 1 Kb in size, while the [h2o](https://cran.r-project.org/package=h2o) package is 170 Mb, and there are Bioconductor binaries that are over 4 Gb!

    -   System requirements: Some packages require additional system dependencies in order to be used.
        For instance, the [rjags](https://cran.r-project.org/package=rjags) package requires a matching installation of the JAGS library.
        Another example is [rJava](https://cran.r-project.org/package=rJava) which requires a Java SDK and also has additional steps needed to configure R for the proper Java installation, which has caused [installation issues for many people](https://stackoverflow.com/questions/tagged/rjava).

5.  Maintenance capacity.
    It is reasonable to have higher confidence in a package that is well-established and that is maintained by developers or teams with a long track record and that maintain many other packages.
    This increases the likelihood that the package will remain on CRAN without interruptions and that the maintainer has an intentional approach to the software life cycle (@sec-lifecycle).

6.  Functionality.
    Some packages implement a critical piece of functionality that is used across many packages.
    In the tidyverse, broadly defined, the rlang, tidyselect, vctrs, and tibble packages are all examples of this.
    By using these packages for tricky tasks like non-standard evaluation or manipulation of vectors and data frames, package authors can avoid re-implementing basic functionality.
    It's easy to think "how hard can it be to write my own X?" when you are focused on the Happy Path[^dependencies-mindset-background-1].
    But a huge part of the value brought by packages like vctrs or tibble is letting someone else worry about edge cases and error handling[^dependencies-mindset-background-2]
    . There is also value in having shared behaviour with other packages, e.g. the tidyverse rules for [name repair](https://vctrs.r-lib.org/reference/vec_as_names.html) or [recycling](https://vctrs.r-lib.org/reference/vector_recycling_rules.html).

[^dependencies-mindset-background-1]: In programming, the Happy Path is the scenario where all the inputs make sense and are exactly how things "should be".
    The Unhappy Path is everything else (objects of length or dimension zero, objects with missing data or dimensions or attributes, objects that don't exist, etc.).

[^dependencies-mindset-background-2]: Before writing your own version of X, have a good look at the bug tracker and test suite for another package that implements X.
    This can be useful for appreciating what is actually involved.

The specifics above hopefully make it clear that package dependencies are not equal.

### Prefer a holistic, balanced, and quantitative approach

Instead of striving for a minimal number of dependencies, we recommend a more holistic, balanced, and quantitative approach.

A holistic approach looks at the project as a whole and asks "who is the primary audience?".
If the audience is other package authors, then a leaner package with fewer dependencies may be more appropriate.
If, instead, the target user is a data scientist or statistician, they will likely already have many popular dependencies installed and would benefit from a more feature-full package.

A balanced approach understands that adding (or removing) dependencies comes with trade-offs.
Adding a dependency gives you additional features, bug fixes, and real-world testing, at the cost of increased installation time, disk space and maintenance, if the dependency has breaking changes.
In some cases it makes sense to *increase* dependencies for a package, even if an implementation already exists.
For instance, base R has a number of different implementations of non-standard evaluation with varying semantics across its functions.
The same used to be true of tidyverse packages as well, but now they all depend on the implementations in the [tidyselect](https://tidyselect.r-lib.org) and [rlang](https://rlang.r-lib.org) packages.
Users benefit from the improved consistency of this feature and individual package developers can let the maintainers of tidyselect and rlang worry about the technical details.

In contrast, removing a dependency lowers installation time, disk space, and avoids potential breaking changes.
However, it means your package will have fewer features or that you must re-implement them yourself.
That, in turn, takes development time and introduces new bugs.
One advantage of using an existing solution is that you'll get the benefit of all the bugs that have already been discovered and fixed.
Especially if the dependency is relied on by many other packages, this is a gift that keeps on giving.

Similar to optimizing performance, if you are worried about the burden of dependencies, it makes sense to address those concerns in a specific and quantitative way.
The experimental [itdepends](https://github.com/r-lib/itdepends) package was created for the [talk](https://www.rstudio.com/resources/rstudioconf-2019/it-depends-a-dialog-about-dependencies/) and [blog post](https://www.tidyverse.org/blog/2019/05/itdepends/) this section is based on.
It is still a useful source of concrete ideas (and code) for analyzing how heavy a dependency is.
The [pak](https://pak.r-lib.org/) package also has several functions that are useful for dependency analysis:

```{r}
#| eval: false
pak::pkg_deps_tree("tibble")
#> tibble 3.1.8 ✨
#> ├─fansi 1.0.3 ✨
#> ├─lifecycle 1.0.3 ✨
#> │ ├─cli 3.4.1 ✨ ⬇ (1.28 MB)
#> │ ├─glue 1.6.2 ✨
#> │ └─rlang 1.0.6 ✨ ⬇ (1.81 MB)
#> ├─magrittr 2.0.3 ✨
#> ├─pillar 1.8.1 ✨ ⬇ (673.95 kB)
#> │ ├─cli
#> │ ├─fansi
#> │ ├─glue
#> │ ├─lifecycle
#> │ ├─rlang
#> │ ├─utf8 1.2.2 ✨
#> │ └─vctrs 0.5.1 ✨ ⬇ (1.82 MB)
#> │   ├─cli
#> │   ├─glue
#> │   ├─lifecycle
#> │   └─rlang
#> ├─pkgconfig 2.0.3 ✨
#> ├─rlang
#> └─vctrs
#>
#> Key:  ✨ new |  ⬇ download

pak::pkg_deps_explain("tibble", "rlang")
#> tibble -> lifecycle -> rlang
#> tibble -> pillar -> lifecycle -> rlang
#> tibble -> pillar -> rlang
#> tibble -> pillar -> vctrs -> lifecycle -> rlang
#> tibble -> pillar -> vctrs -> rlang
#> tibble -> rlang
#> tibble -> vctrs -> lifecycle -> rlang
#> tibble -> vctrs -> rlang
```

### Dependency thoughts specific to the tidyverse

The packages maintained by the tidyverse team play different roles in the ecosystem and are managed accordingly.
For example, the tidyverse and devtools packages are essentially meta-packages that exist for the convenience of an end-user.
Consequently, it is recommended that other packages **should not depend** on tidyverse[^dependencies-mindset-background-3] or devtools (@sec-setup-usage), i.e. these two packages should almost never appear in `Imports`. Instead, a package maintainer should identify and depend on the lower-level package that actually implements the desired functionality.

[^dependencies-mindset-background-3]: There is a blog post that warns people away from depending on the tidyverse package: <https://www.tidyverse.org/blog/2018/06/tidyverse-not-for-packages/>.

In the previous section, we talked about different ways to gauge the weight of a dependency.
Both the tidyverse and devtools can be seen as heavy due to the very high number of recursive dependencies:

```{r}
n_hard_deps <- function(pkg) {
  deps <- tools::package_dependencies(pkg, recursive = TRUE)
  sapply(deps, length)
}

n_hard_deps(c("tidyverse", "devtools"))
```

In contrast, several packages are specifically conceived as low-level packages that implement features that should work and feel the same across the whole ecosystem.
At the time of writing, this includes:

-   rlang, to support tidy eval and throw errors
-   cli and glue, for creating a rich user interface (which includes errors)
-   withr, for managing state responsibly
-   lifecycle, for managing the life cycle of functions and arguments

These are basically regarded as free dependencies and are added to `DESCRIPTION` via `usethis::use_tidy_dependencies()` (which also does a few more things).
It should come as no surprise that these packages have a very small dependency footprint.

```{r}
tools::package_dependencies(c("rlang", "cli", "glue", "withr", "lifecycle"))
```

::: callout-warning
## Submitting to CRAN

Under certain configurations, including those used for incoming CRAN submissions, `R CMD check` issues a `NOTE` if there are 20 or more "non-default" packages in `Imports`:

    N  checking package dependencies (1.5s)
       Imports includes 29 non-default packages.
       Importing from so many packages makes the package vulnerable to any of
       them becoming unavailable.  Move as many as possible to Suggests and
       use conditionally.

Our best advice is to try hard to comply, as it should be rather rare to need so many dependencies and it's best to eliminate any `NOTE` that you can.
Of course, there are exceptions to every rule and perhaps your package is one them.
In that case, you may need to argue your case.
It is certainly true that many CRAN packages violate this threshold.
:::

### Whether to Import or Suggest

The [withr package](https://withr.r-lib.org) is a good case study for deciding whether to list a dependency in `Imports` or `Suggests`.
Withr is very useful for writing tests that clean up after themselves.
Such usage is compatible with listing withr in `Suggests`, since regular users don't need to run the tests.
But sometimes a package might also use withr in its own functions, perhaps to offer its own `with_*()` and `local_*()` functions.
In that case, withr should be listed in `Imports`.

`Imports` and `Suggests` differ in the strength and nature of dependency:

-   `Imports`: packages listed here *must* be present for your package to work.
    Any time your package is installed, those packages will also be installed, if not already present.
    `devtools::load_all()` also checks that all packages in `Imports` are installed.

    Adding a package to `Imports` ensures it will be installed, but it does *not* mean that it will be attached along with your package, i.e. it does not do the equivalent of `library(otherpkg)`[^dependencies-mindset-background-4].
    Inside your package, the best practice is to explicitly refer to external functions using the syntax `package::function()`. This makes it very easy to identify which functions live outside of your package.
    This is especially useful when you read your code in the future.

    If you use a lot of functions from another package, this is rather verbose.
    There's also a minor performance penalty associated with `::` (on the order of 5µs, so it will only matter if you call the function millions of times).
    You'll learn about alternative ways to make functions in other packages available inside your package in @sec-imports.

-   `Suggests`: your package can use these packages, but doesn't require them.
    You might use suggested packages for example datasets, to run tests, build vignettes, or maybe there's only one function that needs the package.

    Packages listed in `Suggests` are not automatically installed along with your package.
    This means that you can't assume the package is available unconditionally.
    Below we show various ways to handle these checks.

[^dependencies-mindset-background-4]: The difference between loading and attaching a package is covered in more detail in @sec-search-path.

`Suggests` isn't terribly relevant for packages where the user base is approximately equal to the development team or for packages that are used in a very predictable context.
In that case, it's reasonable to just use `Imports` for everything.
Using `Suggests` is mostly a courtesy to external users or to accommodate very lean installations.
It can free users from downloading rarely needed packages (especially those that are tricky to install) and lets them get started with your package as quickly as possible.

## Namespace {#sec-dependencies-namespace}

So far, we've explained the mechanics of declaring a dependency in `DESCRIPTION` (@sec-description-imports-suggests) and how to think about the costs and benefits of dependencies (@sec-dependencies-pros-cons).
Before we can explain how to use your dependencies in various parts of your package, we need to establish the concepts of a package namespace and the search path.

### Motivation {#sec-dependencies-namespace-motivation}

As the name suggests, namespaces provide "spaces" for "names".
They provide a context for looking up the value of an object associated with a name.

Without knowing it, you've probably already used namespaces.
For example, have you ever used the `::` operator?
It disambiguates functions with the same name.
For example, both the lubridate and here packages provide a `here()` function.
If you attach lubridate, then here, `here()` will refer to the here version, because the last package attached wins.
But if you attach the packages in the opposite order, `here()` will refer to the lubridate version.

```{r}
#| eval: FALSE
library(lubridate)              library(here)
library(here)                   library(lubridate)

here() # gets here::here()      here() # gets lubridate::here()
```

This can be confusing.
Instead, you can qualify the function call with a specific namespace: `lubridate::here()` and `here::here()`.
Then the order in which the packages are attached won't matter[^dependencies-mindset-background-5].

[^dependencies-mindset-background-5]: We're going to stay focused on packages in this book, but there are other ways than using `::` to address conflicts in end-user code: the [conflicted package](https://conflicted.r-lib.org) and the [`"conflicts.policy"` option](https://developer.r-project.org/Blog/public/2019/03/19/managing-search-path-conflicts/) introduced in base R v3.6.0.

```{r}
#| eval: FALSE
lubridate::here() # gets lubridate::here() NO MATTER WHAT
here::here()      # gets here::here() NO MATTER WHAT
```

As you will see in CROSS-REF, the `package::function()` calling style is also our default recommendation for how to use your dependencies in the code below `R/`, because it eliminates all ambiguity.

But, in the context of package code, the use of `::` is not really our main line of defense against the confusion seen in the example above.
In packages, we rely on namespaces to ensure that every package works the same way regardless of what packages are attached by the user.

Consider the `nrow()` function in base R:

```{r}
nrow
```

It's defined in terms of `dim()`.
So what happens if we override `dim()` with our own definition?
Does `nrow()` break?

```{r}
dim <- function(x) c(1, 1)
dim(mtcars)
nrow(mtcars)
```

Surprisingly, it does not!
That's because when `nrow()` looks for an object called `dim()`, it starts in the base package namespace, so it finds `base::dim()`, not the `dim()` we created in the global environment.
It would be chaos if functions like `nrow()` could be broken by a user redefining `dim()` or by attaching a package that overrides `dim()`.
The package namespace system is what saves us from this fate.

A package's namespace makes it self-contained in two ways: the **imports** and the **exports**.
The **imports** define how a function in one package finds a function in another.
The **exports** specify the functions that your package makes available for external use.

### The `NAMESPACE` file {#sec-dependencies-namespace-file}

The NAMESPACE file is a key player in defining your package's namespace.
Here are selected lines from the `NAMESPACE` file in the testthat package:

    # Generated by roxygen2: do not edit by hand

    S3method(compare,character)
    S3method(print,testthat_results)
    export(compare)
    export(expect_equal)
    import(rlang)
    importFrom(brio,readLines)
    useDynLib(testthat, .registration = TRUE)

The first line announces that this file was not written by hand, but rather is generated by the roxygen2 package.
We'll return to this topic soon, after we discuss the remaining lines.

You can see that the `NAMESPACE` file looks a bit like R code (but it is not).
Each line contains a **directive**: `S3method()`, `export()`, `importFrom()`, and so on.
Each directive describes an R object, and says whether it's exported from this package to be used by others, or it's imported from another package to be used internally.

These directives are the most important in our development approach, in order of frequency:

-   `export()`: export a function (including S3 and S4 generics).
-   `S3method()`: export an S3 method.
-   `importFrom()`: import selected object from another namespace (including S4 generics).
-   `import()`: import all objects from another package's namespace. package.
-   `useDynLib()`: registers routines from a DLL.

There are other directives that we won't cover here, because they are explicitly discouraged or they just rarely come up in our development work.

-   `exportPattern()`: exports all functions that match a pattern. We feel it's safer to always use explicit exports and we avoid the use of this directive.
-   `exportClasses()`, `exportMethods()`, `importClassesFrom()`, `importMethodsFrom()`: export and import S4 classes and methods. We only work in the S4 system when necessary for compatibility with another other package, i.e. we generally don't implement methods or classes that we own with S4. Therefore the S4 coverage in this book is very minimal.

In the devtools workflow, the `NAMESPACE` file is not written by hand!
Instead, we prefer to generate `NAMESPACE` with the roxygen2 package, using specific tags located in a roxygen comment above, e.g., each function's definition in the `R/*.R` files.
We will have much more to say about roxygen comments and the roxygen2 package when we discuss package documentation in @sec-man.
For now, we just lay out the reasons we prefer this method of generating the `NAMESPACE` file:

-   Namespace definitions live next to their associated functions, so when you read the code it's easier to see what's being imported and exported.

-   Roxygen2 abstracts away some of the details of `NAMESPACE`.
    You only need to learn one tag, `@export`, which will automatically generate the right directive for regular functions, S3 methods, S4 methods, and S4 classes.

-   Roxygen2 keeps `NAMESPACE` tidy.
    No matter how many times you use `@importFrom foo bar` in your roxygen comments, you'll only get one `importFrom(foo, bar)` in your `NAMESPACE`.
    Roxygen2 also keeps NAMESPACE organised in a principled order, sorting first by the directive type and then alphabetically.
    Roxygen2 takes away the burden of writing NAMESPACE, while also trying to keep the file as readable as possible.

Note that you can choose to use roxygen2 to generate just `NAMESPACE`, just `man/*.Rd` (@sec-man), or both (as is our practice).
If you don't use any namespace related tags, roxygen2 won't touch `NAMESPACE`.
If you don't use any documentation related tags, roxygen2 won't touch `man/`.

help you avoid conflicts with other packages by specifying which functions are available outside of your package (internal functions are available only within your package and can't easily be used by another package).

Generally, you want to export a minimal set of functions; the fewer you export, the smaller the chance of a conflict.
While conflicts aren't the end of the world because you can always use `::` to disambiguate, they're best avoided where possible, because it makes the lives of your users easier.

https://github.com/hadley/r-pkgs/issues/204

https://adv-r.hadley.nz/environments.html#special-environments

https://adv-r.hadley.nz/environments.html#namespaces

### 

### 

### Search path {#sec-search-path}

To understand why namespaces are important, you need a solid understanding of search paths.
To call a function, R first has to find it.
R does this by first looking in the global environment.
If R doesn't find it there, it looks in the search path, the list of all the packages you have **attached**.
You can see this list by running `search()`.
For example, here's the search path for the code in this book:

```{r}
search()
```

There's an important difference between loading and attaching a package.
Normally when you talk about loading a package you think of `library()`, but that actually attaches the package.

If a package is installed,

-   **Loading** will load code, data and any DLLs; register S3 and S4 methods; and run the `.onLoad()` function.
    After loading, the package is available in memory, but because it's not in the search path, you won't be able to access its components without using `::`.
    Confusingly, `::` will also load a package automatically if it isn't already loaded.
    It's rare to load a package explicitly, but you can do so with `requireNamespace()` or `loadNamespace()`.

-   **Attaching** puts the package in the search path.
    You can't attach a package without first loading it, so both `library()` or `require()` load then attach the package.
    You can see the currently attached packages with `search()`.

If a package isn't installed, loading (and hence attaching) will fail with an error.

To see the differences more clearly, consider two ways of running `expect_that()` from the testthat package.
If we use `library()`, testthat is attached to the search path.
If we use `::`, it's not.

```{r, error = TRUE}
old <- search()
testthat::expect_equal(1, 1)
setdiff(search(), old)
expect_true(TRUE)
    
library(testthat)
expect_equal(1, 1)
setdiff(search(), old)
expect_true(TRUE)
```

There are four functions that make a package available.
They differ based on whether they load or attach, and what happens if the package is not found (i.e., throws an error or returns FALSE).

|        | Throws error         | Returns `FALSE`                         |
|--------|----------------------|-----------------------------------------|
| Load   | `loadNamespace("x")` | `requireNamespace("x", quietly = TRUE)` |
| Attach | `library(x)`         | `require(x, quietly = TRUE)`            |

Of the four, you should only ever use two:

-   Use `library(x)` in data analysis scripts.
    It will throw an error if the package is not installed, and will terminate the script.
    You want to attach the package to save typing.
    Never use `library()` in a package.

-   Use `requireNamespace("x", quietly = TRUE)` inside a package if you want a specific action (e.g. throw an error) depending on whether or not a suggested package is installed.

You never need to use `require()` (`requireNamespace()` is almost always better), or `loadNamespace()` (which is only needed for internal R code).
You should never use `require()` or `library()` in a package: instead, use the `Depends` or `Imports` fields in the `DESCRIPTION`.

https://github.com/hadley/r-pkgs/issues/588 is about require()

Now's a good time to come back to an important issue which we glossed over earlier.
What's the difference between `Depends` and `Imports` in the `DESCRIPTION`?
When should you use one or the other?

Listing a package in either `Depends` or `Imports` ensures that it's installed when needed.
The main difference is that where `Imports` just *loads* the package, `Depends` *attaches* it.
There are no other differences.
The rest of the advice in this chapter applies whether or not the package is in `Depends` or `Imports`.

Unless there is a good reason otherwise, you should always list packages in `Imports` not `Depends`.
That's because a good package is self-contained, and minimises changes to the global environment (including the search path).
The only exception is if your package is designed to be used in conjunction with another package.
For example, the [analogue](https://github.com/gavinsimpson/analogue) package builds on top of [vegan](https://github.com/vegandevs/vegan).
It's not useful without vegan, so it has vegan in `Depends` instead of `Imports`.
Similarly, ggplot2 should really `Depend` on scales, rather than `Import`ing it.

TODO: the new example should probably be devtools and usethis https://github.com/hadley/r-pkgs/issues/608

Now that you understand the importance of the namespace, let's dive into the nitty gritty details.
The two sides of the package namespace, imports and exports, are both described by the `NAMESPACE`.
You'll learn what this file looks like in the next section.
In the section after that, you'll learn the details of exporting and importing functions and other objects.

## Imports {#sec-imports}

-   in your functions, below R/
-   in your tests, below tests/
-   in your help topics, below man/
-   in your vignettes and articles, below vignettes/

`NAMESPACE` also controls which external functions can be used by your package without having to use `::`.

It's confusing that both `DESCRIPTION` (through the `Imports` field) and `NAMESPACE` (through import directives) seem to be involved in imports.
This is just an unfortunate choice of names.
The `Imports` field really has nothing to do with functions imported into the namespace: it just makes sure the package is installed when your package is.
It doesn't make functions available.
You need to import functions in exactly the same way regardless of whether or not the package is attached.

`Depends` is just a convenience for the user: if your package is attached, it also attaches all packages listed in `Depends`.
If your package is loaded, packages in `Depends` are loaded, but not attached, so you need to qualify function names with `::` or specifically import them.

It's common for packages to be listed in `Imports` in `DESCRIPTION`, but not in `NAMESPACE`.
The converse is not true.
Every package mentioned in `NAMESPACE` must also be present in the `Imports` or `Depends` fields.

### How to use functionality from an Imported package {#import-r}

how to use an Import-ed package in your package's functions

If you are using just a few functions from another package, my recommendation is to note the package name in the `Imports:` field of the `DESCRIPTION` file and call the function(s) explicitly using `::`, e.g., `pkg::fun()`.

If you are using functions repeatedly, you can avoid `::` by importing the function with `@importFrom pkg fun`.
Operators can also be imported in a similar manner, e.g., `@importFrom magrittr %>%`.

Alternatively, if you are repeatedly using many functions from another package, you can import all of them using `@import package`.
This is the least recommended solution because it makes your code harder to read (you can't tell where a function is coming from), and if you `@import` many packages, it increases the chance of conflicting function names.

https://github.com/hadley/r-pkgs/issues/828 how to not use a function listed in Imports

### How to use functionality from a Suggested package

Inside a function in your own package, check for the availability of a suggested package with `requireNamespace("pkg", quietly = TRUE)`.
There are two basic scenarios:

```{r}
# the suggested package is required 
my_fun <- function(a, b) {
  if (!requireNamespace("pkg", quietly = TRUE)) {
    stop(
      "Package \"pkg\" must be installed to use this function.",
      call. = FALSE
    )
  }
  # code that includes calls such as pkg::f()
}

# the suggested package is optional; a fallback method is available
my_fun <- function(a, b) {
  if (requireNamespace("pkg", quietly = TRUE)) {
    pkg::f()
  } else {
    g()
  }
}
```

The rlang package has some useful functions for checking package availability.
Here's how the checks around a suggested package could look if you use rlang:

```{r}
# the suggested package is required 
my_fun <- function(a, b) {
  rlang::check_installed("pkg", reason = "to use `my_fun()`")
  # code that includes calls such as pkg::f()
}

# the suggested package is optional; a fallback method is available
my_fun <- function(a, b) {
  if (rlang::is_installed("pkg")) {
    pkg::f()
  } else {
    g()
  }
}
```

These rlang functions have handy features for programming, such as vectorization over `pkg`, classed errors with a data payload, and, for `check_installed()`, an offer to install the needed package in an interactive session.

Another common place to use a suggested package is in an example and here we often guard with `require()` (but you'll also see `requireNamespace()` used for this).
This example is from `ggplot2::coord_map()`.

```{r eval = FALSE}
#' @examples
#' if (require("maps")) {
#'   nz <- map_data("nz")
#'   # Prepare a map of NZ
#'   nzmap <- ggplot(nz, aes(x = long, y = lat, group = group)) +
#'     geom_polygon(fill = "white", colour = "black")
#'  
#'   # Plot it in cartesian coordinates
#'   nzmap
#' }
```

An example is basically the only place where we would use `require()` inside a package.

Another place you might use a suggested package is in a vignette.
The tidyverse team generally writes vignettes as if all suggested packages are available.
But if you choose to use suggested packages conditionally in your vignettes, the knitr chunk options `purl` and `eval` may be useful for achieving this.
See @sec-vignettes for more discussion of vignettes.

#### Whether and how to guard in a test {#sec-suggested-packages-and-tests}

As with vignettes, the tidyverse team does not usually guard the use of a suggested package in a test.
In general, for vignettes and tests, we assume all suggested packages are available.
The motivation for this posture is self-consistency and pragmatism.
The key packages needed to run tests or build vignettes (e.g. testthat or knitr) appear in `Suggests`, not in `Imports` or `Depends`.
Therefore, if the tests are actually executing or the vignettes are being built, that implies that an expansive notion of package dependencies has been applied.
Also, empirically, in every important scenario of running `R CMD check`, the suggested packages are installed.
This is generally true for CRAN and we ensure that it's true in our own automated checks.
However, it's important to note that other package maintainers take a different stance and choose to protect all usage of suggested packages in their tests and vignettes.

Sometimes even the tidyverse team makes an exception and guards the use of a suggested package in a test.
Here's a test from ggplot2, which uses `testthat::skip_if_not_installed()` to skip execution if the suggested sf package is not available.

```{r eval = FALSE}
test_that("basic plot builds without error", {
  skip_if_not_installed("sf")

  nc_tiny_coords <- matrix(
    c(-81.473, -81.741, -81.67, -81.345, -81.266, -81.24, -81.473,
      36.234, 36.392, 36.59, 36.573, 36.437, 36.365, 36.234),
    ncol = 2
  )

  nc <- sf::st_as_sf(
    data_frame(
      NAME = "ashe",
      geometry = sf::st_sfc(sf::st_polygon(list(nc_tiny_coords)), crs = 4326)
    )
  )

  expect_doppelganger("sf-polygons", ggplot(nc) + geom_sf() + coord_sf())
})
```

What might justify the use of `skip_if_not_installed()`?
In this case, the sf package can be nontrivial to install and it is conceivable that a contributor would want to run the remaining tests, even if sf is not available.

Finally, note that `testthat::skip_if_not_installed(pkg, minimum_version = "x.y.z")` can be used to conditionally skip a test based on the version of the other package.

### Nonstandard dependencies

In packages developed with devtools, you may see `DESCRIPTION` files that use a couple other nonstandard fields for package dependencies specific to development tasks.

The `Remotes` field can be used when you need to install a dependency from a nonstandard place, i.e. from somewhere besides CRAN or Bioconductor.
One common example of this is when you're developing against a development version of one of your dependencies.
During this time, you'll want to install the dependency from its development repository, which is often GitHub.
The way to specify various remote sources is described in a [devtools vignette](https://devtools.r-lib.org/articles/dependencies.html).

<!-- TODO: long-term, a better link will presumably be https://pak.r-lib.org/reference/pak_package_sources.html, once the pivot from remotes to pak is further along. -->

The dependency and any minimum version requirement still need to be declared in the normal way in, e.g., `Imports`.
`usethis::use_dev_package()` helps to make the necessary changes in `DESCRIPTION`.
If your package temporarily relies on a development version of usethis, the affected `DESCRIPTION` fields might evolve like this:

<!-- This is unlovely, but I just wanted to get the content down "on paper". It's easier to convey with a concrete example. -->

    Stable -->               Dev -->                       Stable again
    ----------------------   ---------------------------   ----------------------
    Package: yourpkg         Package: yourpkg              Package: yourpkg
    Version: 1.0.0           Version: 1.0.0.9000           Version: 1.1.0
    Imports:                 Imports:                      Imports: 
        usethis (>= 2.1.3)       usethis (>= 2.1.3.9000)       usethis (>= 2.2.0)
                             Remotes:   
                                 r-lib/usethis 

It's important to note that you should not submit your package to CRAN in the intermediate state, meaning with a `Remotes` field and with a dependency required at a version that's not available from CRAN or Bioconductor.
For CRAN packages, this can only be a temporary development state, eventually resolved when the dependency updates on CRAN and you can bump your minimum version accordingly.

You may also see devtools-developed packages with packages listed in `DESCRIPTION` fields in the form of `Config/Needs/*`.
This pattern takes advantage of the fact that fields prefixed with `Config/` are ignored by CRAN and also do not trigger a NOTE about "Unknown, possibly mis-spelled, fields in `DESCRIPTION`".

```{=html}
<!--
https://github.com/wch/r-source/blob/de49776d9fe54cb4580fbbd04906b40fe2f6117e/src/library/tools/R/QC.R#L7133
https://github.com/wch/r-source/blob/efacf56dcf2f880b9db8eafa28d49a08d56e861e/src/library/tools/R/utils.R#L1316-L1389
-->
```
The use of `Config/Needs/*` is not directly related to devtools.
It's more accurate to say that it's associated with continuous integration workflows made available to the community at <https://github.com/r-lib/actions/> and exposed via functions such as `usethis::use_github_actions()`.
A `Config/Needs/*` field tells the [`setup-r-dependencies`](https://github.com/r-lib/actions/tree/master/setup-r-dependencies#readme) GitHub Action about extra packages that need to be installed.

`Config/Needs/website` is the most common and it provides a place to specify packages that aren't a formal dependency, but that must be present in order to build the package's website.
On the left is an example of what might appear in `DESCRIPTION` for a package that uses various tidyverse packages in the non-vignette articles on its website, which is also formatted with styling that lives in the `tidyverse/template` GitHub repo.
On the right is the corresponding excerpt from the configuration of the workflow that builds and deploys the website.

    in DESCRIPTION                  in .github/workflows/pkgdown.yaml
    --------------------------      ---------------------------------
    Config/Needs/website:           - uses: r-lib/actions/setup-r-dependencies@v1
        tidyverse,                    with:
        tidyverse/tidytemplate          extra-packages: pkgdown
                                        needs: website

Continuous integration and package websites are discussed more in ??
and ??,
respectively.
*These chapters are a yet-to-be-(re)written task for the 2nd edition.*

<!-- TODO: Link to CI and pkgdown material when it has been written and/or revised. -->

The `Config/Needs/*` convention is handy because it allows a developer to use `DESCRIPTION` as their definitive record of package dependencies, while maintaining a clean distinction between true runtime dependencies versus those that are only needed for specialized development tasks.

<!-- re: describing different types of dependencies, another term you see for "runtime" dependency is "production" -->

## Exports {#exports}

For a function to be usable outside of your package, you must **export** it.
When you create a new package with `usethis::create_package()`, nothing is exported at first.
You can still experiment interactively with `load_all()` (since that loads all functions, not just those that are exported).
But if you install and reload the package, you'll notice that no functions are available.

In the devtools workflow and this book, the NAMESPACE file is automatically generated from special roxygen comments in the R/\*.R files.

To export an object, put `@export` in its roxygen block.
For example:

```{r}
#' @export
foo <- function(x, y, z) {
  ...
}
```

This will then generate `export()`, `exportMethods()`, `exportClass()` or `S3method()` depending on the type of the object.

You export functions that you want other people to use.
Exported functions must be documented, and you must be cautious when changing their interface --- other people are using them!
Generally, it's better to export too little than too much.
It's easy to export things that you didn't before; it's hard to stop exporting a function because it might break existing code.
Always err on the side of caution, and simplicity.
It's easier to give people more functionality than it is to take away stuff they're used to.

I believe that packages that have a wide audience should strive to do one thing and do it well.
All functions in a package should be related to a single problem (or a set of closely related problems).
Any functions not related to that purpose should not be exported.
For example, most of my packages have a `utils.R` file that contains many small functions that are useful for me, but aren't part of the core purpose of those packages.
I never export these functions.

```{r}
# Defaults for NULL values
`%||%` <- function(a, b) if (is.null(a)) b else a

# Remove NULLs from a list
compact <- function(x) {
  x[!vapply(x, is.null, logical(1))]
}
```

That said, if you're creating a package for yourself, it's far less important to be so disciplined.
Because you know what's in your package, it's fine to have a local "misc" package that contains a passel of functions that you find useful.
But I don't think you should release such a package.

The following sections describe what you should export if you're using S3, S4 or RC.
NOT CURRENTLY TRUE!

https://github.com/hadley/r-pkgs/issues/576 how and why to re-export a function

### Workflow {#namespace-workflow}

Generating the namespace with roxygen2 is just like generating function documentation with roxygen2.
You use roxygen2 blocks (starting with `#'`) and tags (starting with `@`).
The workflow is the same:

1.  Add roxygen comments to your `.R` files.

2.  Run `devtools::document()` (or press Ctrl/Cmd + Shift + D in RStudio) to convert roxygen comments to `.Rd` files.

3.  Look at `NAMESPACE` and run tests to check that the specification is correct.

4.  Rinse and repeat until the correct functions are exported.

## To place somewhere

https://github.com/hadley/r-pkgs/issues/447 .onLoad(), .onAttach() what they are and advice to not touch the random number generator there

https://github.com/hadley/r-pkgs/issues/485 why you don't want Depends

https://github.com/hadley/r-pkgs/issues/657 Decide what's happening with S3, S4, R6, R7
