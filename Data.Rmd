# Data {#sec-data}

```{r, echo = FALSE}
source("common.R")
status("restructuring")
```

## Introduction

It's often useful to include data in a package.
If the primary purpose of a package is to distribute useful functions, example datasets make it easier to write excellent documentation.
These datasets can be hand-crafted to provide compelling use cases for the functions in the package.
Here are some examples of this type of package data:

-   [tidyr](https://tidyr.tidyverse.org/reference/index.html#data): `billboard` (song rankings), `who` (tuberculosis data from the World Health Organization)
-   [dplyr](https://dplyr.tidyverse.org/reference/index.html#data): `starwars` (Star Wars characters), `storms` (storm tracks)

At the other extreme, some packages exist solely for the purpose of distributing data, along with its documentation.
These are sometimes called "data packages".
A data package can be a nice way to share example data across multiple packages.
It is also a useful technique for getting relatively large, static files out of a more function-oriented package, which might require more frequent updates.
Here are some examples of data packages:

-   [nycflights13](https://nycflights13.tidyverse.org)
-   [babynames](https://github.com/hadley/babynames)

Finally, many packages benefit from having internal data that is used for internal purposes, but that is not directly exposed to the users of the package.

In this chapter we describe useful mechanisms for including data in your package.
The practical details differ depending on who needs access to the data, how often it changes, and what they will do with it:

-   If you want to store R objects and make them available to the user, put them in `data/`.
    This is the best place to put example datasets.
    All the concrete examples above for data in a package and data as a package use this mechanism.

-   If you want to store R objects for your own use as a developer, put them in `R/sysdata.rda`.
    This is the best place to put internal data that your functions need.

-   If you want to store data in some raw, non-R-specific form and make it available to the user, put it in `inst/extdata/`.
    For example, readr and readxl each use this mechanism to provide a collection of delimited files and Excel workbooks, respectively.

-   If you want to store dynamic data that reflects the internal state of your package within a single R session, use an environment.
    This technique is not as common or well-known as those above, but can be very useful in specific situations.

-   If you want to store data persistently across R sessions, such as configuration or user-specific data, use one of the officially sanctioned locations.

## Exported data {#sec-data-data}

The most common location for package data is (surprise!) `data/`.
We recommend that each file in this directory be an `.rda` file created by `save()` containing a single R object, with the same name as the file.
The easiest way to achieve this is to use `usethis::use_data()`.

```{r, eval = FALSE}
my_pkg_data <- sample(1000)
usethis::use_data(my_pkg_data)
```

Let's imagine we are working on a package named "pkg".
The snippet above creates `data/my_pkg_data.rda` inside the source of the pkg package and adds `LazyData: true` in your `DESCRIPTION`.
This makes the `my_pkg_data` R object available to users of pkg via `pkg::my_pkg_data` or, after attaching pkg with `library(pkg)`, as `my_pkg_data`.

The snippet above is something the maintainer executes once (or every time they need to update `my_pkg_data`).
This is workflow code and should **not** appear in the `R/` directory of the source package.
(We'll talk about a suitable place to keep this code below.) For larger datasets, you may want to experiment with the compression setting, which is under the control of the `compress` argument.
The default is "bzip2", but sometimes "gzip" or "xz" can create smaller files.

It's possible to use other types of files below `data/`, but we don't recommend it because `.rda` files are already fast, small, and explicit.
The other possibilities are described in the documentation for `utils::data()` and in the [Data in packages](https://rstudio.github.io/r-manuals/r-exts/Creating-R-packages.html#data-in-packages) section of Writing R Extensions.
In terms of advice to package authors, the help topic for `data()` seems to implicitly make the same recommendations as we do above:

-   Store one R object in each `data/*.rda` file
-   Use the same name for that object and its `.rda` file
-   Use lazy-loading, by default

If the `DESCRIPTION` contains `LazyData: true`, then datasets will be lazily loaded.
This means that they won't occupy any memory until you use them.
The following example shows memory usage before and after loading the nycflights13 package.
You can see that memory usage doesn't change until you inspect the `flights` dataset stored inside the package.

```{r}
lobstr::mem_used()
library(nycflights13)
lobstr::mem_used()

invisible(flights)
lobstr::mem_used()
```

We recommend that you include `LazyData: true` in your `DESCRIPTION` if you are shipping `.rda` files below `data/`.
If you use `use_data()` to create such datasets, it will automatically make this modification to `DESCRIPTION` for you.

::: callout-warning
It is important to note that lazily-loaded datasets do **not** need to be pre-loaded with `utils::data()` and, in fact, it's usually best to avoid doing so.
Above, once we did `library(nycflights13)`, we could immediately access `flights`.
There is no call to `data(flights)`, because it is not necessary.

There are specific downsides to `data(some_pkg_data)` calls that support a policy of only using `data()` when it is actually necessary, i.e. for datasets that would not be available otherwise:

-   By default, `data(some_pkg_data)`, creates one or more objects in the user's global workspace. There is the potential to silently overwrite pre-existing objects with new values.
-   There is also no guarantee that `data(foo)` will create exactly one object named "foo". It could create more than one object and/or objects with totally different names.

One argument in favor of calls like `data(some_pkg_data, package = "pkg")` that are not strictly necessary is that it clarifies which package provides `some_pkg_data`.
We prefer alternatives that don't modify the global workspace, such as a code comment or access via `pkg::some_pkg_data`.

This excerpt from the documentation of `data()` conveys that it is largely of historical importance:

> `data()` was originally intended to allow users to load datasets from packages for use in their examples, and as such it loaded the datasets into the workspace `.GlobalEnv`.
> This avoided having large datasets in memory when not in use: that need has been almost entirely superseded by lazy-loading of datasets.
:::

### Preserve the origin story of package data {#sec-data-data-raw}

Often, the data you include in `data/` is a cleaned up version of raw data you've gathered from elsewhere.
We highly recommend taking the time to include the code used to do this in the source version of your package.
This makes it easy for you to update or reproduce your version of the data.
This data-creating script is also a natural place to leave comments about important properties of the data, i.e. which features are important for downstream usage in package documentation.

We suggest that you keep this code in one or more `.R` files below `data-raw/`.
You don't want it in the bundled version of your package, so this folder should be listed in `.Rbuildignore`.
usethis has a convenience function that can be called when you first adopt the `data-raw/` practice or when you add an additional `.R` file to the folder:

```{r, eval = FALSE}
usethis::use_data_raw()

usethis::use_data_raw("my_pkg_data")
```

`use_data_raw()` creates the `data-raw/` folder and lists it in `.Rbuildignore`.
A typical script in `data-raw/` includes code to prepare a dataset and ends with a call to `use_data()`.

These data packages all use the approach recommended here for `data-raw/`:

-   [babynames](https://github.com/hadley/babynames)
-   [nycflights13](https://github.com/hadley/nycflights13)
-   [gapminder](https://github.com/jennybc/gapminder)

::: callout-tip
## ggplot2: A cautionary tale

We have a confession to make: the origins of many of ggplot2's example datasets has been lost in the sands of time.
In the grand scheme of things, this is not a huge problem, but maintenance is certainly more pleasant when a package's assets can be reconstructed *de novo* and easily updated as necessary.
:::

::: callout-warning
## Submitting to CRAN

Generally, package data should be smaller than a megabyte - if it's larger you'll need to argue for an exemption.
<!-- TODO: insert a crosslink to the best place in yet-to-be-revised chapter on the CRAN release process. --> This is usually easier to do if the data is in its own package and won't be updated frequently, i.e. if you approach this as a dedicated "data package".
For reference, the babynames and nycflights packages have had a release once every one to two years, since they first appeared on CRAN.

If you are bumping up against size issues, you should be intentional with regards to the method of data compression.
The default for `usethis::use_data(compress =)` is "bzip2", whereas the default for `save(compress =)` is (effectively) "gzip", and "xz" is yet another valid option.

You'll have to experiment with different compression methods and make this decision empirically.
`tools::resaveRdaFiles("data/")` automates this process, but doesn't inform you of which compression method was chosen.
You can learn this after the fact with `tools::checkRdaFiles()`.
Assuming you are keeping track of the code to generate your data, it would be wise to update the corresponding `use_data(compress =)` call below `data-raw/` and re-generate the `.rda` cleanly.
:::

### Documenting datasets {#documenting-data}

Objects in `data/` are always effectively exported (they use a slightly different mechanism than `NAMESPACE` but the details are not important).
This means that they must be documented.
Documenting data is like documenting a function with a few minor differences.
Instead of documenting the data directly, you document the name of the dataset and save it in `R/`.
For example, the roxygen2 block used to document the `who` data in tidyr is saved in `R/data.R` and looks something like this:

```{r, eval = FALSE}
#' World Health Organization TB data
#'
#' A subset of data from the World Health Organization Global Tuberculosis
#' Report ...
#'
#' @format ## `who`
#' A data frame with 7,240 rows and 60 columns:
#' \describe{
#'   \item{country}{Country name}
#'   \item{iso2, iso3}{2 & 3 letter ISO country codes}
#'   \item{year}{Year}
#'   ...
#' }
#' @source <https://www.who.int/teams/global-tuberculosis-programme/data>
"who"
```

There are two roxygen tags that are especially important for documenting datasets:

-   `@format` gives an overview of the dataset.
    For data frames, you should include a definition list that describes each variable.
    It's usually a good idea to describe variables' units here.

-   `@source` provides details of where you got the data, often a URL.

Never `@export` a data set.

### Non-ASCII characters in data

The R objects you store in `data/*.rda` often contain strings, with the most common example being character columns in a data frame.
If you can constrain these strings to only use ASCII characters, it certainly makes things simpler.
But of course, there are plenty of legitimate reasons why package data might include non-ASCII characters.

In that case, we recommend that you embrace the [UTF-8 Everywhere manifesto](http://utf8everywhere.org) and use the UTF-8 encoding.
The `DESCRIPTION` file placed by `usethis::create_package()` always includes `Encoding: UTF-8`, so by default a devtools-produced package already advertises that it will use UTF-8.

Making sure that the strings embedded in your package data have the intended encoding is something you accomplish in your data preparation code, i.e. in the R scripts below `data-raw/`.
You can use `Encoding()` to learn the current encoding of the elements in a character vector and functions such as `enc2utf8()` or `iconv()` to convert between encodings.

::: callout-warning
## Submitting to CRAN

If you have UTF-8-encoded strings in your package data, you may see this from `R CMD check`:

    -   checking data for non-ASCII characters ... NOTE
        Note: found 352 marked UTF-8 strings

This `NOTE` is truly informational.
It requires no action from you.
As long as you actually intend to have UTF-8 strings in your package data, all is well.

Ironically, this `NOTE` is actually suppressed by `R CMD check --as-cran`, despite the fact that this note does appear in the check results once a package is on CRAN (which implies that CRAN does not necessarily check with `--as-cran`).
By default, `devtools::check()` sets the `--as-cran` flag and therefore does not transmit this `NOTE`.
But you can surface it with `check(cran = FALSE, env_vars = c("_R_CHECK_PACKAGE_DATASETS_SUPPRESS_NOTES_" = "false"))`.
:::

<!-- TODO: Offer some advice for those who have non-ASCII strings in their package and it is a surprise (so, it's not intentional). The best resource I have found so far for this is `tools:::.check_package_datasets()`. Perhaps devtools should get a function that does a ground-up implementation of such a search for non-ASCII strings. -->

<!-- https://github.com/wch/r-source/blob/f6737799b169710006b040f72f9abc5e09180229/src/library/tools/R/QC.R#L4672 -->

## Internal data {#data-sysdata}

Sometimes your package functions need access to pre-computed data.
If you put these objects in `data/`, they'll also be available to package users, which is not appropriate.
Sometimes the objects you need are small and simple enough that you can define them with `c()` or `data.frame()` in the code below `R/`, perhaps in `R/data.R`.
Larger or more complicated objects should be stored in your package's internal data in `R/sysdata.rda`.

Here are some examples of internal package data:

-   Two colour-related packages, [munsell](https://github.com/cwickham/munsell) and [dichromat](https://cran.r-project.org/web/packages/dichromat/index.html), use `R/sysdata.rda` to store large tables of colour data.
-   [googledrive](https://github.com/tidyverse/googledrive) and [googlesheets4](https://github.com/tidyverse/googlesheets4) wrap the Google Drive and Google Sheets APIs, respectively. Both use `R/sysdata.rda` to store data derived from a so-called [Discovery Document](https://developers.google.com/discovery/v1/reference/apis) which "describes the surface of the API, how to access the API and how API requests and responses are structured".

<!-- Another example I noted: readr + data-raw/date-symbols.R + date_symbols -->

The easiest way to create `R/sysdata.rda` is to use `usethis::use_data(internal = TRUE)`:

```{r, eval = FALSE}
internal_this <- ...
internal_that <- ...

usethis::use_data(internal_this, internal_that, internal = TRUE)
```

Unlike `data/`, where you use one `.rda` file per exported data object, you store all of your internal data objects together in the single file `R/sysdata.rda`.

Let's imagine we are working on a package named "pkg".
The snippet above creates `R/sysdata.rda` inside the source of the pkg package.
This makes the objects `internal_this` and `internal_that` available for use inside of the functions defined below `R/` and in the tests.
During interactive development, `internal_this` and `internal_that` are available after a call to `devtools::load_all()`, just like an internal function.

Much of the advice given for external data holds for internal data as well:

-   It's a good idea to store the code that generates your individual internal data objects, as well as the `use_data()` call that writes all of them into `R/sysdata.rda`. This is workflow code that belongs below `data-raw/`, not below `R/`.
-   `usethis::use_data_raw()` can be used to initiate the use of `data-raw/` or to initiate a new `.R` script there.
-   If your package is uncomfortably large, experiment with different values of `compress` in `use_data(internal = TRUE)`.

There are also key distinctions, where the handling of internal and external data differs:

-   Objects in `R/sysdata.rda` are not exported (they shouldn't be), so they don't need to be documented.
-   Usage of `R/sysdata.rda` has no impact on DESCRIPTION, i.e. the need to specify the `LazyData` field is strictly about the exported data below `data/`.

## Raw data file {#sec-data-extdata}

If you want to show examples of loading/parsing raw data, put the original files in `inst/extdata/`.
When the package is installed, all files (and folders) in `inst/` are moved up one level to the top-level directory, which is why they can't have names that conflict with standard parts of an R package, like `R/` or `DESCRIPTION` .
The files below `inst/extdata/` in the source package will be located below `extdata/` in the corresponding installed package.

The main reason to include such files is when a key part of a package's functionality is to act on an external file.
Examples of such packages include:

-   readr, which reads rectangular data out of delimited files
-   readxl, which reads rectangular data of of Excel spreadsheets
-   xml2, which can read XML and HTML from file
-   archive, which can read archive files, such as tar or ZIP

All of these packages have one of more example files below `inst/extdata/`, which are useful for writing documentation and tests.

It is also common for data packages to provide, e.g., a csv version of the package data that is also provided as an R object.
Examples of such packages include:

-   palmerpenguins: `penguins` and `penguins_raw` are also represented as `extdata/penguins.csv` and `extdata/penguins_raw.csv`
-   gapminder: `gapminder`, `continent_colors`, and `country_colors` are also represented as `extdata/gapminder.tsv`, `extdata/continent-colors.tsv`, and `extdata/country-colors.tsv`

There has two payoffs: First, it gives teachers and other expositors more to work with once they decide to use a specific dataset.
If you've started teaching R with `palmerpenguins::penguins` or `gapminder::gapminder` and you want to introduce data import, it can be helpful to students if their first use of a new command, like `readr::read_csv()` or `read.csv()`, is applied to a familiar dataset.
They have pre-existing intuition about the expected result.
Finally, if package data evolves over time, having a csv or other plain text representation in the source package can make it easier to what's changed.

### Filepaths

The path to a package file found below `extdata/` clearly depends on the local environment, i.e. it depends on where installed packages live on that machine.
The base function `system.file()` can report the full path to files distributed with an R package.
It can also be useful to *list* the files distributed with an R package.

```{r}
system.file("extdata", package = "readxl") |> list.files()

system.file("extdata", "clippy.xlsx", package = "readxl")
```

These filepaths present yet another workflow dilemma: When you're developing your package, you engage with it in its source form, but your users engage with it as an installed package.
Happily, devtools provides a shim for `base::system.file()` that is activated by `load_all()`.
This makes interactive calls to `system.file()` from the global environment and calls from within the package namespace "just work".

Be aware that, by default, `system.file()` returns the empty string, not an error, for a file that does not exist.

```{r}
system.file("extdata", "I_do_not_exist.csv", package = "readr")
```

If you want to force a failure in this case, specify `mustWork = TRUE`:

```{r error = TRUE}
system.file("extdata", "I_do_not_exist.csv", package = "readr", mustWork = TRUE)
```

The [fs package](https://fs.r-lib.org) offers the `path_package()` function, which has several nice features, and which we recommend where the fs dependency makes sense:

-   It errors if the filepath does not exist.
-   It throws distinct errors when the package does not exist vs. when the file does not exist within the package.
-   During development, it works for interactive calls, calls from within the loaded package's namespace, and even for calls originating in dependencies.

```{r error = TRUE}
fs::path_package("extdata", package = "idonotexist")

fs::path_package("extdata", "I_do_not_exist.csv", package = "readr")

fs::path_package("extdata", "chickens.csv", package = "readr")
```

### `pkg_example()` path helpers

We like to offer convenience functions that make example files easy to access.
These are just user-friendly wrappers around `system.file()` or `fs::path_package()`, but can have added features, such as the ability to list the example files.
Here's the definition and some usage of `readxl::read_example()`:

```{r, eval = FALSE}
readxl_example <- function(path = NULL) {
  if (is.null(path)) {
    dir(system.file("extdata", package = "readxl"))
  } else {
    system.file("extdata", path, package = "readxl", mustWork = TRUE)
  }
}
```

```{r}
readxl::readxl_example()

readxl::readxl_example("clippy.xlsx")
```

## Internal state

Sometimes there's information that multiple functions from your package need to access that:

-   Must be determined at runtime, not build time. It might even be dynamic.
-   Doesn't make sense to pass in via a function argument. Often it's some obscure detail that a user shouldn't even know about.

A great way to manage such data is to use an *environment*.[^data-1]
This environment must be created a build time, but you can populate it with values at runtime and update those values over the course of an R session.
This works because environments have reference semantics (whereas more pedestrian R objects, such as atomic vectors, lists, or data frames have value semantics).

[^data-1]: If you don't know much about R environments and what makes them special, a great resource is the [Environments chapter](https://adv-r.hadley.nz/environments.html) of Advanced R.

Consider a package that can store the user's favorite letters or numbers.
You might start out with code like this in a file below `R/`:

```{r eval = FALSE}
favorite_letters <- letters[1:3]

#' Report my favorite letters
#' @export
mfl <- function() {
  favorite_letters
}

#' Change my favorite letters
#' @export
set_mfl <- function(l = letters[24:26]) {
  favorite_letters <<- l
  favorite_letters
}
```

`favorite_letters` is initialized to ("a", "b", "c") when the package is built.
The user can then inspect `favorite_letters` with `mfl()`, at which point they'll probably want to register *their* favorite letters with `set_mfl()`.
Note that we've used the super assignment operator `<<-` in `set_mfl()` in the hope that this will reach up into the package environment and modify the internal data object `favorite_letters`.
But a call to `set_mfl()` fails like so:

```{r, eval = FALSE}
set_mfl(c("j", "f", "b"))
#> Error in set_mfl(c("j", "f", "b")): cannot change value of locked binding for
#> 'favorite_letters'
```

Because `favorite_letters` is a regular character vector, modification requires making a copy and rebinding the name `favorite_letters` to this new value.
And that is what's disallowed: you can't change the binding for objects in the package namespace (well, at least not without trying harder than this).

However, if we maintain our internal state within an internal package environment, we can modify objects contained in the environment and even add completely new objects.
Here's an alternative implementation that uses an internal environment named `the`.

```{r, eval = FALSE}
the <- new.env(parent = emptyenv())
the$favorite_letters <- letters[1:3]

#' Report my favorite letters
#' @export
mfl2 <- function() {
  the$favorite_letters
}

#' Change my favorite letters
#' @export
set_mfl2 <- function(l = letters[24:26]) {
  the$favorite_letters <- l
  the$favorite_letters
}
```

Now a user *can* record their favorite letters:

```{r, eval = FALSE}
mfl2()
#> [1] "a" "b" "c"

set_mfl2(c("j", "f", "b"))
#> [1] "j" "f" "b"

mfl2()
#> [1] "j" "f" "b"
```

We often like to use the name "the" for an internal package environment, because it allows you to refer to the objects inside in a very natural way, such as `the$token`, meaning "the token".
It is also important to specify `parent = emptyenv()` for such an internal environment, as you generally don't want the environment to inherit from any other (nonempty) environment.

Here are some examples of how packages use this technique:

-   Various functions in the googledrive package need to know the file ID for the current user's home directory on Google Drive. This is an eye-watering string of 40 seemingly random characters that means nothing to a human. It would be inhumane to expect a user to know this or to pass it into every function. Instead, googledrive determines this ID upon first need, then caches it for later use.
-   TODO: Need 1-2 more examples.

The blog post [Package-Wide Variables/Cache in R Packages](https://trestletech.com/2013/04/package-wide-variablescache-in-r-package/) gives a more detailed development of this technique.

<!-- I've always felt like Hermione's beaded bag / Bag of Holding is a great analogy for this environment technique. As long as you've got this bag, you can keep whatever you like in it. Should I try to develop this? -->

## Persistent user data

state that persists within a user

https://github.com/hadley/r-pkgs/issues/818

`?tools::R_user_dir()`

[rappdirs](https://rappdirs.r-lib.org)
